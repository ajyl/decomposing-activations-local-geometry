{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8c1aaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import os\n",
    "import torch\n",
    " llm_utils.activation_generator import ActivationGenerator\n",
    "from data_utils.concept_dataset import SupervisedConceptDataset\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "\n",
    "# ## Configuration\n",
    "#\n",
    "# - `data_path`: Path to the dataset / examples used for training and analysis.\n",
    "# - `model_name`: A **TransformerLens-supported** model to extract activations from. We default to a small model (`gpt2-small`) for fast iteration; swap in larger models if you have GPU memory/compute.\n",
    "# - `layers`: Which layer to inspect and factorize.\n",
    "# - `data_device`: Where data tensors live during preprocessing (CPU by default).\n",
    "# - `model_device`: Where the model runs for activation extraction and generation. Use `mps` on Apple Silicon, `cuda` on NVIDIA GPUs, or `cpu` if needed.\n",
    "# - `factorization_mode`: Which activation stream to factorize:\n",
    "#   - `residual`: a general-purpose choice that often yields clean, interpretable structure.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90d6e5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_path = \"./data/supervised.json\"\n",
    "model_name = \"gpt2-small\"\n",
    "layers = [4]\n",
    "data_device = \"cuda\"\n",
    "model_device = \"cuda\"\n",
    "factorization_mode = \"residual\"\n",
    "\n",
    "\n",
    "# ### Loading and Generating Data\n",
    "#\n",
    "# In this tutorial we use our own abstractions for generating activations and loading data. In the end, you need to generate a loader for training MFA. Feel free to swap out with a different method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3af1e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "act_generator = ActivationGenerator(\n",
    "    model_name,\n",
    "    model_device=model_device,\n",
    "    data_device=data_device,\n",
    "    mode=factorization_mode,\n",
    "    initialize=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bef4cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dataset_obj = SupervisedConceptDataset(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b3507b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building vocab frequency: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3600/3600 [00:00<00:00, 37904.14it/s]\n",
      "Generating multi-layer activations with freq: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3600/3600 [01:35<00:00, 37.51it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "activations, _ = act_generator.generate_multiple_layer_activations_and_freq(\n",
    "    dataset_obj, layers\n",
    ")\n",
    "\n",
    "\n",
    "# We additionally load tokens in order to later interpret the subspaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd34de64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting token IDs: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3600/3600 [00:03<00:00, 1176.96it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from llm_utils.activation_generator import extract_token_ids_sample_ids_and_labels\n",
    "\n",
    "tokens, _, _ = extract_token_ids_sample_ids_and_labels(dataset_obj, act_generator)\n",
    "\n",
    "\n",
    "# Creating the loaders from extracted activations\n",
    "# To make this notebook work on lower compute we utilize only 250k activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59b17f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# your raw data\n",
    "X_all = activations[0][0:250_000]\n",
    "tokens = tokens[0:250_000]\n",
    "\n",
    "# make a single dataset\n",
    "full_ds = TensorDataset(X_all, tokens)\n",
    "\n",
    "loader = DataLoader(\n",
    "    full_ds,\n",
    "    batch_size=128,\n",
    "    shuffle=True,  # always shuffle your training set\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "# if you still want a standalone token loader (e.g. for some other pass):\n",
    "token_loader = DataLoader(tokens, batch_size=128)\n",
    "\n",
    "\n",
    "# ### Initialization\n",
    "#\n",
    "# As described in the paper we tested three options for initialization.\n",
    "# We found that K-Means often works well, with random point initialization also successful (random weights often fail).\n",
    "# In this tutorial we show how to use K-Means as its the most complicated of the three, and we provide an implementation that works on torch.\n",
    "\n",
    "# We must decide on how much of the data to run our K-Means. Since K-Means is slower, our implmentation allows to decide a pool size which will be randomly sampled. Additionally, for efficiency it uses a projected K-Means.\n",
    "#\n",
    "# In this tutorial we use the 20% dataset which consists of 600k activations in order to speed it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e84d4421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "pool_size = round(len(loader.dataset) / 5)\n",
    "pool_size\n",
    "\n",
    "\n",
    "# We use 500 centroids, this is an arbitrary number and you can reduce it to capture more broad subspaces or increase to produce more semantic covariances.\n",
    "#\n",
    "# Should run in 3-5 minutes. For shorter runtime, sample points as the centroids (second cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0d683c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from initializations.projected_knn import ReservoirKMeans\n",
    "\n",
    "num_centroids = 500\n",
    "\n",
    "knn = ReservoirKMeans(\n",
    "    num_centroids,\n",
    "    pool_size=pool_size,\n",
    "    vocab_size=50257,\n",
    "    device=model_device,\n",
    "    proj_dim=32,\n",
    ")\n",
    "centroids = knn.fit(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "453f19c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# random points\n",
    "N = X_all.shape[0]\n",
    "idx = torch.randperm(N, device=X_all.device)[\n",
    "    :num_centroids\n",
    "]  # sample without replacement\n",
    "centroids = X_all[idx]\n",
    "\n",
    "\n",
    "# ### Training\n",
    "#\n",
    "# We train using Negative Log Likelihood. We provided an implementation of a very simple training loop.\n",
    "# We use R = 10 (covariance dim), feel free to experiment with different values. It mostly depends on the intrinsic dimension of the data.\n",
    "#\n",
    "# We train for 10 epochs, which is sufficient for the follow up interpretation and steering. For evaluations, would want to train until convergence.\n",
    "#\n",
    "# Should take about 10-15 minutes. Feel free to train for less epochs, a couple epochs are often enough to see results (depends on dataset size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "813b68e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Step 001900 Train NLL=1421.015905: : 1954it [00:05, 341.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 01] train NLL=1418.286274  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 02 | Step 001900 Train NLL=1288.547953: : 1954it [00:05, 341.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 02] train NLL=1287.693992  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 03 | Step 001900 Train NLL=1247.182531: : 1954it [00:05, 341.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 03] train NLL=1246.881022  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 04 | Step 001900 Train NLL=1221.958015: : 1954it [00:05, 341.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 04] train NLL=1221.854058  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 05 | Step 001900 Train NLL=1204.325863: : 1954it [00:05, 341.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 05] train NLL=1204.190597  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 06 | Step 001900 Train NLL=1191.228009: : 1954it [00:05, 341.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 06] train NLL=1191.193339  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 07 | Step 001900 Train NLL=1181.751503: : 1954it [00:05, 341.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 07] train NLL=1181.772298  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 08 | Step 001900 Train NLL=1174.310107: : 1954it [00:05, 341.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 08] train NLL=1174.370478  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 09 | Step 001900 Train NLL=1168.420521: : 1954it [00:05, 341.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 09] train NLL=1168.277099  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Step 001900 Train NLL=1163.551707: : 1954it [00:05, 341.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 10] train NLL=1163.508294  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Step 001900 Train NLL=1159.803898: : 1954it [00:05, 341.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 11] train NLL=1159.612256  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Step 001900 Train NLL=1156.218978: : 1954it [00:05, 341.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 12] train NLL=1156.141009  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Step 001900 Train NLL=1153.304783: : 1954it [00:05, 341.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 13] train NLL=1153.194633  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Step 001900 Train NLL=1150.748046: : 1954it [00:05, 341.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 14] train NLL=1150.811943  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Step 001900 Train NLL=1148.515049: : 1954it [00:05, 341.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 15] train NLL=1148.395080  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Step 001900 Train NLL=1146.195546: : 1954it [00:05, 341.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 16] train NLL=1146.195315  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Step 001900 Train NLL=1144.035929: : 1954it [00:05, 341.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 17] train NLL=1144.031506  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Step 001900 Train NLL=1142.230502: : 1954it [00:05, 341.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 18] train NLL=1142.310246  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Step 001900 Train NLL=1140.869365: : 1954it [00:05, 341.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 19] train NLL=1140.782110  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Step 001900 Train NLL=1139.314096: : 1954it [00:05, 340.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 20] train NLL=1139.446246  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Step 001900 Train NLL=1138.178250: : 1954it [00:05, 341.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 21] train NLL=1138.182968  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Step 001900 Train NLL=1136.769148: : 1954it [00:05, 341.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 22] train NLL=1136.964856  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Step 001900 Train NLL=1135.528299: : 1954it [00:05, 341.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 23] train NLL=1135.858110  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Step 001900 Train NLL=1134.757595: : 1954it [00:05, 340.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 24] train NLL=1134.892211  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Step 001900 Train NLL=1134.048775: : 1954it [00:05, 340.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 25] train NLL=1134.068917  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Step 001900 Train NLL=1133.039825: : 1954it [00:05, 341.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 26] train NLL=1133.322301  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Step 001900 Train NLL=1132.525923: : 1954it [00:05, 341.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 27] train NLL=1132.586279  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Step 001900 Train NLL=1132.037190: : 1954it [00:05, 341.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 28] train NLL=1132.017979  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Step 001900 Train NLL=1131.295171: : 1954it [00:05, 341.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 29] train NLL=1131.477194  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Step 001900 Train NLL=1130.983244: : 1954it [00:05, 341.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 30] train NLL=1130.908918  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31 | Step 001900 Train NLL=1130.190547: : 1954it [00:05, 341.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 31] train NLL=1130.315383  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32 | Step 001900 Train NLL=1129.660018: : 1954it [00:05, 341.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 32] train NLL=1129.753168  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33 | Step 001900 Train NLL=1129.180140: : 1954it [00:05, 341.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 33] train NLL=1129.294397  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34 | Step 001900 Train NLL=1128.687216: : 1954it [00:05, 341.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 34] train NLL=1128.848197  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35 | Step 001900 Train NLL=1128.431843: : 1954it [00:05, 341.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 35] train NLL=1128.341498  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36 | Step 001900 Train NLL=1127.789738: : 1954it [00:05, 341.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 36] train NLL=1127.939815  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37 | Step 001900 Train NLL=1127.431546: : 1954it [00:05, 341.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 37] train NLL=1127.590118  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38 | Step 001900 Train NLL=1127.237357: : 1954it [00:05, 341.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 38] train NLL=1127.257268  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39 | Step 001900 Train NLL=1127.044427: : 1954it [00:05, 341.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 39] train NLL=1126.939278  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40 | Step 001900 Train NLL=1126.237027: : 1954it [00:05, 341.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 40] train NLL=1126.535949  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41 | Step 001900 Train NLL=1126.180649: : 1954it [00:05, 341.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 41] train NLL=1126.218555  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42 | Step 001900 Train NLL=1125.559360: : 1954it [00:05, 341.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 42] train NLL=1125.882275  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43 | Step 001900 Train NLL=1125.750348: : 1954it [00:05, 341.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 43] train NLL=1125.634371  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44 | Step 001900 Train NLL=1125.426441: : 1954it [00:05, 341.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 44] train NLL=1125.353298  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45 | Step 001900 Train NLL=1125.197917: : 1954it [00:05, 341.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 45] train NLL=1125.115928  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46 | Step 001900 Train NLL=1124.748831: : 1954it [00:05, 341.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 46] train NLL=1124.859256  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47 | Step 001900 Train NLL=1124.486846: : 1954it [00:05, 341.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 47] train NLL=1124.592017  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48 | Step 001900 Train NLL=1124.355607: : 1954it [00:05, 341.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 48] train NLL=1124.318234  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49 | Step 001900 Train NLL=1123.928176: : 1954it [00:05, 341.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 49] train NLL=1124.087896  val NLL=nan ** best **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50 | Step 001900 Train NLL=1123.820522: : 1954it [00:05, 341.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 50] train NLL=1123.872130  val NLL=nan ** best **\n",
      "Restored best model from epoch 50 with metric=1123.872130\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_epoch': 50, 'best_metric': 1123.8721303203124}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from modeling.mfa import MFA\n",
    "from modeling.train import train_nll\n",
    "\n",
    "model = MFA(centroids=centroids, rank=10).to(model_device)\n",
    "train_nll(model, loader, epochs=50, lr=1e-3)\n",
    "\n",
    "\n",
    "# ### Interpretation\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c649ca91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will first inspect the top likelihood samples per Gaussian, then will visualize the gaussians in order to show the within Gaussian separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e011157",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def my_token_to_str(tok_id):\n",
    "    return act_generator.model.to_string(tok_id)\n",
    "\n",
    "\n",
    "# To interpret the Gaussians, we calculate for each activation in the loader the likelihood for each Gaussian. Then we present the last token of the top likelihood samples, in order to understand the theme.\n",
    "#\n",
    "# This cell could take a bit to run, in our setup around 4 min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aba77328",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from analysis.subspace_interpretation import get_top_strings_per_concept\n",
    "\n",
    "results = get_top_strings_per_concept(\n",
    "    model, loader, my_token_to_str, score=\"likelihood\"\n",
    ")\n",
    "\n",
    "\n",
    "# We now view the top likelihood samples, we try to sample from them so that they don't all look very similar. To better understand the Gaussian its advised to look at the whole distribution of contexts that belong to the Gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbac7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import random\n",
    "\n",
    "N_RESULTS = 25\n",
    "N_LINES = 10\n",
    "TOP_POOL = 5000\n",
    "SEED = 0\n",
    "\n",
    "random.seed(SEED)\n",
    "\n",
    "for i, (r, w) in enumerate(list(results.items())[:N_RESULTS], start=0):\n",
    "    pool = w[: min(TOP_POOL, len(w))]\n",
    "    sample = random.sample(pool, k=min(N_LINES, len(pool)))  # no repeats\n",
    "\n",
    "    print(f\"\\n[{i}]\\n\" + \"-\" * 40)\n",
    "    for line in sample:\n",
    "        print(\"  - \" + str(line).replace(\"\\n\", \"\\\\n\"))\n",
    "\n",
    "\n",
    "# #### Visualizing\n",
    "#\n",
    "# We move to visualizing the Gaussians, in order to see how the activations distribute within.\n",
    "# To do so, we first calculate the latent dimensions (z) for each point, then plot with the loadings acting as the axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f16701",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import analysis.subspace_visualization as sv\n",
    "\n",
    "k_to_visualize = 20\n",
    "\n",
    "coords = sv.project_loader_to_subspace(\n",
    "    model, loader, k=k_to_visualize, token_to_str=my_token_to_str\n",
    ")\n",
    "\n",
    "\n",
    "# Here we visualize in 2d using two loadings. The variance is spread out across 10 dimensions and loadings do not necessarily reflect directions of maximal variance, rather together they serve as a basis for the subspace of maximal structured variance. To better understand the structure either plot in 3D, use PCA on the subspace, or lower R. Additional discussion in the paper!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a203cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sv.plot_subspace_scatter(coords, dims=(0, 8), max_labels=250)\n",
    "\n",
    "\n",
    "# ## Steering\n",
    "# In this part we will show how we can steer using both the centroids and the loadings.\n",
    "# To show the effect of steering we will inspect the top promoted tokens of an intervention. While the centroids promote, loadings can also suppress, so it is useful to look at the top absolute logit difference.\n",
    "#\n",
    "# Important to note, steering produces different results across different models. Some models require weaker alpha values or different steering methods. Tweak the parameters if things don't work out. Will update soon with additional steering methods that work especially well for MFA using the fact that we know source and target distributions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c16d4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# import and helpers\n",
    "\n",
    "from intervention.mfa_steering import MFASteerer\n",
    "\n",
    "\n",
    "def print_logit_diff(model, logits_before, logits_after, top_k: int = 10):\n",
    "    \"\"\"\n",
    "    Prints the tokens with the largest positive and negative logit changes\n",
    "    (after - before) for the last position in the sequence.\n",
    "    \"\"\"\n",
    "    # Select the logits for the last token in the sequence (shape: [vocab_size])\n",
    "    logits_before_last = logits_before[0, -1, :]\n",
    "    logits_after_last = logits_after[0, -1, :]\n",
    "\n",
    "    # Compute the difference in logits (after - before)\n",
    "    delta_logits = logits_after_last - logits_before_last\n",
    "\n",
    "    # --- Top positive changes ---\n",
    "    pos_vals, pos_idx = torch.topk(delta_logits, k=top_k)\n",
    "    print(f\"Top {top_k} positive logit changes:\")\n",
    "    for token_id, change in zip(pos_idx, pos_vals):\n",
    "        token_str = model.to_str_tokens([token_id])  # adjust to your tokenizer API\n",
    "        print(f\"  Token: {token_str},  Δlogit: {change.item():.4f}\")\n",
    "\n",
    "    # --- Top negative changes ---\n",
    "    # by taking topk of -delta_logits we get the most negative values\n",
    "    neg_vals, neg_idx = torch.topk(-delta_logits, k=top_k)\n",
    "    print(f\"\\nTop {top_k} negative logit changes:\")\n",
    "    for token_id, neg_change in zip(neg_idx, neg_vals):\n",
    "        token_str = model.to_str_tokens([token_id])\n",
    "        # negate neg_change to show the actual delta_logits value\n",
    "        print(f\"  Token: {token_str},  Δlogit: {-neg_change.item():.4f}\")\n",
    "\n",
    "\n",
    "def get_logit_diff(model, logits_before, logits_after):\n",
    "    # Select the logits for the last token in the sequence (shape: [vocab_size])\n",
    "    logits_before_last = logits_before[0, -1, :]\n",
    "    logits_after_last = logits_after[0, -1, :]\n",
    "\n",
    "    # Compute the difference in logits (after - before)\n",
    "    delta_logits = logits_after_last - logits_before_last\n",
    "\n",
    "    # Get the top 10 tokens with the largest positive increase\n",
    "    top_increases, top_indices = torch.topk(abs(delta_logits), k=20)\n",
    "    final_strings = []\n",
    "    for token_id, increase in zip(top_indices, top_increases):\n",
    "        # Convert token ID to string using your model's tokenizer\n",
    "        # Here we assume feature_processor._model.to_str_tokens returns a readable token string\n",
    "        token_str = model.to_str_tokens([token_id])\n",
    "        final_strings.append(f\"Token: {token_str}, Score: {increase.item():.4f}\")\n",
    "    return final_strings\n",
    "\n",
    "\n",
    "# ### Centroid Steering\n",
    "#\n",
    "# We interpolate towards the centroid using:\n",
    "#\n",
    "# (1-alpha)*x + alpha * mu\n",
    "#\n",
    "# We interpolate since the centroid defines absolute position, for more disscussion on this see the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43bffd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "steerer = MFASteerer(act_generator.model, model)\n",
    "\n",
    "\n",
    "# We define intervention strength, layer and prompt.\n",
    "# Alpha = 1 means we replace with the centroid, and often produces a strong causal effect. Best to use lower values, based on the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04f4bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "alpha = 0.6\n",
    "layer = 4\n",
    "prompt = \"I think that\"\n",
    "factor_num = 20\n",
    "\n",
    "base_logits = act_generator.model(act_generator.model.to_tokens(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cce92c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "intervened_logits = steerer.intervene(\n",
    "    prompt,\n",
    "    layers=[layer],\n",
    "    alpha=alpha,\n",
    "    k=factor_num,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3f4271",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print_logit_diff(act_generator.model, base_logits, intervened_logits, top_k=15)\n",
    "\n",
    "\n",
    "# We see that by intervening towards the centroid of Gaussian 20 (depicted Gaussian above), we promoted tokens related to research.\n",
    "#\n",
    "# Next, we intervene using the local subspace as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35081182",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "z = torch.zeros(\n",
    "    10,\n",
    ")\n",
    "z[0] = 20\n",
    "z[8] = -10\n",
    "\n",
    "intervened_logits = steerer.intervene_to_latent_two_stage(\n",
    "    prompt,\n",
    "    layers=[layer],\n",
    "    alpha_centroid=alpha,\n",
    "    z=z,\n",
    "    k=factor_num,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31c8790",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print_logit_diff(act_generator.model, base_logits, intervened_logits, top_k=8)\n",
    "\n",
    "\n",
    "# We see that by setting the z vector to point towards the \"dissertation\" area within the Gaussian (see figure a couple cells back), we promote \"dissertation\" related tokens!\n",
    "#\n",
    "# It's important to note that we only set 2 coordinates, but to get a better effect its best to define z using all latent dimensions (R=10) as the variation is not isolated to a few loadings.\n",
    "\n",
    "# ### Final Note\n",
    "#\n",
    "# Hopefully the tutorial was a good start, for any additional questions about the paper or utilizing MFA feel free to reach out!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
